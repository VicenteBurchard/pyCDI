{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c46255f-2900-41a4-bed9-5497231c7d20",
   "metadata": {},
   "source": [
    "# The Composite Drought Index using Cloud-based satellite imagery\n",
    "\n",
    "This notebook will introduce the **Composite Drought Index (CDI)** and how it can be readily estimated using python and open-source satellite products readily available through the **SpatioTemporal Asset Catalogs (STAC)** framework. \n",
    "\n",
    "The CDI incorporates **three main components** that characterize drought detection and severity:\n",
    "\n",
    "1. precipitation deficit: **Precipiation Drought Index (PDI)**\n",
    "2. excess temperature: **Temperature Drought Index (TDI)**\n",
    "3. vegetation response: **Vegetation Drought Index (VDI)**\n",
    "\n",
    "In this example, we will use [ERA5-Land](https://cds.climate.copernicus.eu/cdsapp#!/dataset/reanalysis-era5-land?tab=overview) from the Copernicus Climate Change Service to calculate the **PDI** and **TDI**, while we will use [MODIS 8-day Surface Reflectance](https://lpdaac.usgs.gov/products/mod09gqv061/) product to calculate the **Normalize-Difference Vegetation Index (NDVI)** as the response variable to produce the **VDI**.\n",
    "\n",
    "The general form of each drought index (DI) is:\n",
    "$$\n",
    "DI = \\frac {\\mu_{IP}}{\\mu_{LTM}}\\sqrt{\\frac {RL_{IP}}{RL_{LTM}}}\n",
    "$$\n",
    "\n",
    "where $\\mu_{IP}$ actual conditions during the the interest period (IP), $\\mu_{LTM}$ is the long-term mean (i.e. normal conditions) and the right side refers to the ratio between the run length $RL_{IP}$ of continuous deficit (in the case of precipiration and NDVI) or excess (in the case of temperature) compared to the long-term-mean $RL_{LTM}$. \n",
    "\n",
    "The run length highlights the enduring presence of adverse conditions, signifying continuous drought conditions. In the case of PDI and VDI, this run duration represents the span within the interest period (IP) where precipitation or NDVI consistently falls below their respective long-term averages. Conversely, for TDI, the run duration signifies the period within the IP where the temperature remains consistently above its long-term average for the corresponding time unit (e.g., month).\n",
    "\n",
    "In this example, we use a **monthly time step** and the interest period uses a **the 3-month moving window** .\n",
    "\n",
    "The CDI is then computed as the weighted average of the PDI and VDI and TDI, as shown below on equation:\n",
    "\n",
    "$$\n",
    "CDI = w_{PDI} PDI + w_{TDI}TDI + w_{VDI}VDI\n",
    "$$\n",
    "here $w$ are the weights which are 50% for $w_{PDI}$ and $w_{TDI}$=$w_{VDI}$=25% \n",
    "\n",
    "We will produce a CDI time series over **the Borena region** in Southern Ethiopia, which is particularly vulnerable to drought and their impacts. \n",
    "\n",
    "This notebook will showcase the use of open-source satellite-based datasets readily available in the STAC to produce an early warning system for drought events.\n",
    "\n",
    "![study area](images/Borena_LULC_DEM.png)\n",
    "\n",
    "This notebook will follow the following structure:\n",
    "\n",
    "## General structure of notebook\n",
    "\n",
    "#### 1. Precipiation Drought Index (PDI)\n",
    "\n",
    "#### 2. Temperature Drought Index (TDI)\n",
    "\n",
    "#### 3. Vegetation Drought Index (VDI)\n",
    "\n",
    "#### 4. Merging to compute Composite Drought Index (CDI)\n",
    "\n",
    "\n",
    "\n",
    "## Acknowledgements\n",
    "\n",
    "This work was done within the [EO Africa](https://www.eoafrica-rd.org/) [R&D research projects](https://www.eoafrica-rd.org/research/research-projects-2023-2024/) funded by the European Space Agency (ESA)\n",
    "\n",
    "![EO AFRICA](images/EOAFRICA-logo.png) \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34442ed5-0b67-4aa2-a3a0-4200bb961cdf",
   "metadata": {},
   "source": [
    "## 0. import libraries\n",
    "Before begining, make sure to view the readme and install all the dependencies needed to run this code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c84999-2024-4608-8819-62e85fe348ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib \n",
    "\n",
    "from pathlib import Path\n",
    "from cubo import cubo\n",
    "from rasterio.crs import CRS\n",
    "import gdal_utils as gu\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyCDI import cdi_functions as cdi\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "import rasterio\n",
    "from rasterio.transform import from_bounds\n",
    "import calendar\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "print('libraries imported correctly')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae40fcc-2223-48ff-845c-b18069fd4f66",
   "metadata": {},
   "source": [
    "# 1. PDI estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc02ed3c-873b-4aa9-bcba-54ee8cea394e",
   "metadata": {},
   "source": [
    "## Using DestinationEarth to get ERA-5 data \n",
    "We will access ERA-5 land data from DestinatinEarth https://platform.destine.eu/ \n",
    "\n",
    "To access datasets on Earth Data Hub you need to instruct your tools (xarray, Zarr, etc.) to use EDH personal access token when downloading the data.\n",
    "\n",
    "To obtain a personal access token you first need to register to the Destination Earth platform. \n",
    "\n",
    "Then you can go to Earth Data Hub account settings **(https://earthdatahub.destine.eu/account-settings)** where you can find your default personal access token or create others. After retrieving your personal access token, please cut and paste it below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d242ccf-cf89-4820-8e4f-28b4f77da5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAT = \"edh_pat_773681a0c232ec917dbb3722dbb6ed29ff4a7ce7272e3e4e78501168823af5043af4223923b07d16ab956f1b55b2011f\"\n",
    "\n",
    "#e.g. PAT=\"edh_pat_44bbb7e9192a4c6bb47ddf07d07564eee5d17de8dfc48f7118f88e3bc4a4157f8fe2403f5aa0a2d53441b6922ea9a33a\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54a8b9e-2cbf-4ad5-b199-e6a60b682716",
   "metadata": {},
   "source": [
    "# Data access\n",
    "\n",
    "We will open the data from **Earth Data Hub** as an **xarray dataset**. See tutorials available here: https://earthdatahub.destine.eu/tutorials\n",
    "\n",
    "Here, we will open the **ERA5 single levels (hourly time step)**: https://earthdatahub.destine.eu/collections/era5/datasets/reanalysis-era5-single-levels \n",
    "\n",
    "For the full catalogue of collections available in **Earth Data Hub**, you can visit here: https://earthdatahub.destine.eu/catalogue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2106a55e-0f04-4f0d-b3e1-b4658b134957",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Acquiring ERA5 data from EarthDataHub server [...] ')\n",
    "# open data set as xarray dataset using your PAT\n",
    "ds = xr.open_dataset(\n",
    "    f\"https://edh:{PAT}@data.earthdatahub.destine.eu/era5/reanalysis-era5-single-levels-v0.zarr\",\n",
    "    chunks={},\n",
    "    engine=\"zarr\",\n",
    ")\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c11d64e-bf0b-490d-a585-8a68053892b1",
   "metadata": {},
   "source": [
    "## ERA5 data attributes\n",
    "\n",
    "We have the following variables in the dataset\n",
    "\n",
    "| Short Name | Units | Description |\n",
    "|-----------|-------|-------------|\n",
    "| d2m | K | 2 metre dewpoint temperature |\n",
    "| msl | Pa | Mean sea level pressure |\n",
    "| sp | Pa | Surface pressure |\n",
    "| sst | K | Sea surface temperature |\n",
    "| t2m | K | 2 metre temperature |\n",
    "| tp | m | Total precipitation |\n",
    "| u10 | m s⁻¹ | 10 metre U wind component |\n",
    "| v10 | m s⁻¹ | 10 metre V wind component |\n",
    "\n",
    "We will first work with **precipitation data (i.e. tp)** which is stored as units of meters (m). We will need to convert to mm.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec5f8e6-584e-4906-88a7-b254b536e128",
   "metadata": {},
   "source": [
    "## Select area of interest\n",
    "As first step, we will need to extract the dataset from DestinationEarth and import it as an xarray dataset. We need to specify the start and end date and also geographical location of center of the area of interest.\n",
    "\n",
    "in the example, the centroid of Borena in **lon = 38.18749189093533 lat = 4.428931591589981** but we will select the corners of region in lat-lon coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba45007-96e3-4ba4-bd44-4abbaa77ea5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat = 4.428931591589981\n",
    "lon = 38.18749189093533\n",
    "\n",
    "# select centroid of area of interest (Borena Region, Ethiopia)\n",
    "upper_left = (7,36) # lat,lon\n",
    "lower_right = (3,40) # lat, lon\n",
    "\n",
    "# select precipitation (tp) from dataset\n",
    "# convert to mm\n",
    "precip = ds.tp.astype(\"float32\") * 1000\n",
    "precip.attrs[\"units\"] = \"mm\"\n",
    "precip_borena = precip.sel(**{\"latitude\": slice(upper_left[0], lower_right[0]), \"longitude\": slice(upper_left[1], lower_right[1])})\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5acb8d93-9171-4b79-88d8-cf4cb1b37122",
   "metadata": {},
   "source": [
    "## Convert to monthly time step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e094050-815d-4074-b84f-01cc1ac09e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Resampling precipiation to a monthly time step [...]')\n",
    "precip_borena_monthly = precip_borena.resample(valid_time=\"MS\").sum()\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17bc0afb-8714-4a0d-8b9a-ed45e4596b89",
   "metadata": {},
   "source": [
    "# Select time period\n",
    "Now we select the time period. To obtain long-term means, we should ideally use at least **20-30 years of data**. \n",
    "\n",
    "In this case, to limit processing time, we will process fewer years as a demonstratation i.e. **5 years: 2018-2022**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642b1d97-8430-45aa-91eb-ef128ed0c6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select start and end date\n",
    "start_date = '2018-01-01'\n",
    "end_date = '2022-12-31'\n",
    "\n",
    "precip_timeperiod = precip_borena_monthly.sel(valid_time=slice(start_date, end_date))\n",
    "print('Done!')\n",
    "precip_timeperiod"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb7d88a-c7ed-4fb9-8986-04f2d6d43cd7",
   "metadata": {},
   "source": [
    "## Extract data\n",
    "\n",
    "Now that we have the selected time period and area of interest, we can compute it to work with data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e30701-1296-4794-87e9-b981fa3c1972",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print('Computing dataset selection to memory [...]')\n",
    "da = precip_timeperiod.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca8acfb-224e-4adf-ac61-f74365694060",
   "metadata": {},
   "source": [
    "## Add projection and georefencing parameters\n",
    "We also need to add projection information to the arrays, necessary to obtain georefenced rasters when we output results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998e6e72-6be1-4c62-8c1e-0df7c73c497d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lon_min, lon_max = da['longitude'].min().item(), da['longitude'].max().item()\n",
    "lat_min, lat_max = da['latitude'].min().item(), da['latitude'].max().item()\n",
    "width = da.sizes['longitude']\n",
    "height = da.sizes['latitude']\n",
    "\n",
    "lats =  da.latitude.values\n",
    "longs =  da.longitude.values\n",
    "\n",
    "transform = from_bounds(lon_min, lat_min, lon_max, lat_max, width, height)\n",
    "gt = (transform[2],  # top-left x\n",
    "      transform[0],  # pixel width\n",
    "      transform[1],  # rotation x\n",
    "      transform[5],  # top-left y\n",
    "      transform[3],  # rotation y\n",
    "      transform[4])  # pixel height (usually negative)\n",
    "proj = CRS.from_epsg(4326).wkt\n",
    "da = da.rename({'valid_time': 'time'})\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322cadb6-9cc6-43af-8f50-16f4aa163bb8",
   "metadata": {},
   "source": [
    "## Visualize monthly precipitation data\n",
    "As an example visualize a year data of monthly rainfall. Below you can select the year (default=2021) to visualize.\n",
    "We will also open the Borena region shapfile to contextualize the region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6060999c-6cad-45d3-9cf2-5005df483e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open borena region shapefile \n",
    "shp_file = Path() / 'CDI_data' / 'roi_info' / 'Borena_outline.geojson'\n",
    "\n",
    "shp = gpd.read_file(str(shp_file))\n",
    "\n",
    "# make sure CRS is lat/lon\n",
    "shp = shp.to_crs(epsg=4326)\n",
    "proj_map = ccrs.PlateCarree()\n",
    "\n",
    "# Select year to visualize \n",
    "year = 2021\n",
    "\n",
    "# filter the data array to year selected \n",
    "da_year = da.sel(time=str(year))\n",
    "da_year = da_year.rio.write_crs(\"EPSG:4326\")\n",
    "\n",
    "print(f'Preparing figure of monthly precipitation maps for {year}...\\n')\n",
    "\n",
    "fig, axes = plt.subplots(\n",
    "    4, 3,\n",
    "    figsize=(12, 16),\n",
    "    subplot_kw={\"projection\": proj_map},\n",
    "    constrained_layout=True)\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    da_month = da_year.isel(time=i)\n",
    "    norm = colors.Normalize(vmin=0, vmax=160)\n",
    "\n",
    "    # precipitation plot\n",
    "    im = da_month.plot(\n",
    "        ax=ax,\n",
    "        transform=proj_map,\n",
    "        cmap=\"Blues\",\n",
    "        add_colorbar=False,\n",
    "        norm=norm)\n",
    "    \n",
    "    # shapefile overlay\n",
    "    shp.boundary.plot(\n",
    "        ax=ax,\n",
    "        edgecolor=\"black\",\n",
    "        linewidth=1)\n",
    "\n",
    "    # titles\n",
    "    month = da_month.time.dt.strftime(\"%B\").item()\n",
    "    ax.set_title(month)\n",
    "\n",
    "    # optional map cosmetics\n",
    "    #ax.coastlines(resolution=\"110m\", linewidth=0.8)\n",
    "    ax.set_extent([\n",
    "        longs.min(),\n",
    "        longs.max(),\n",
    "        lats.min(),\n",
    "        lats.max()])\n",
    "    \n",
    "    gl = ax.gridlines(\n",
    "        crs=ccrs.PlateCarree(),\n",
    "        draw_labels=True,\n",
    "        linewidth=0.5,\n",
    "        color=\"gray\",\n",
    "        alpha=0.6,\n",
    "        linestyle=\"--\")\n",
    "\n",
    "    gl.top_labels = False\n",
    "    gl.right_labels = False\n",
    "    gl.xlabel_style = {\"size\": 9}\n",
    "    gl.ylabel_style = {\"size\": 9}\n",
    "\n",
    "# shared colorbar\n",
    "cbar = fig.colorbar(\n",
    "        im,\n",
    "        ax=axes,\n",
    "        orientation=\"horizontal\",\n",
    "        fraction=0.05,\n",
    "        pad=0.05)\n",
    "\n",
    "cbar.set_label(\"Precipitation (mm/month)\")\n",
    "\n",
    "fig.suptitle(f\"Monthly Precipitation for {year}\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34cb0ab6-3565-42a9-8e34-a5b0c4460001",
   "metadata": {},
   "source": [
    "## 1.1 Calculation of Long-term-mean (LTM) of Precipitation\n",
    "Monthly precipitation anomalies need a long-term-mean (LTM) in order to quanitfy how 'abnormal' or anamoulous is the rainfall amount compared to 'normal' conditions.\n",
    "\n",
    "Normally, to obtain the LTM, we would need at least 30 years of data to have confidence of 'normal' conditions. In this case, as example and to limit processing time, we will only calculate the long-term mean for the years selected which by default are between 2015-2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c5b85f-1efb-44bd-8be7-31b802ac640c",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_steps = pd.to_datetime(da['time'].values)\n",
    "years = np.array(time_steps.year)\n",
    "\n",
    "# select outfolder to save LTM inputs\n",
    "outfolder_ltm = Path() / 'CDI_data' / 'inputs_downloads' / 'Precip' / 'LTM'\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77ef99a-1d12-4145-b359-cb7476bb63a8",
   "metadata": {},
   "source": [
    "Since calculating the LTM may take some time, if the LTM were already produced you can directly import them by setting ltm_produced=True. If it is the first time calculating or you want to calculate it again set ltm_produced=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b314dd2c-70e4-419f-84de-773c73101f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "ltm_produced = True\n",
    "if ltm_produced:\n",
    "    # get mean data\n",
    "    mean_ltm_folder = outfolder_ltm / 'mean'\n",
    "    mean_img_list = sorted(list(mean_ltm_folder.glob('*.tif')))\n",
    "    P_ltm_ds = gu.rasterlist2dict(mean_img_list)\n",
    "    \n",
    "    # get RL data\n",
    "    rl_img_folder = outfolder_ltm / 'RL'\n",
    "    rl_img_list = sorted(list(rl_img_folder.glob('*.tif')))\n",
    "    P_rl_ltm_ds = gu.rasterlist2dict(rl_img_list)\n",
    "\n",
    "    proj, gt, x_size, y_size, extent, center_geo, bands = gu.raster_info(mean_img_list[0])\n",
    "    longs = np.linspace(extent[0], extent[2], x_size)\n",
    "    lats = np.linspace(extent[3], extent[1], y_size)\n",
    "    \n",
    "else:\n",
    "    P_ltm_ds, P_rl_ltm_ds = cdi.compute_ltm(da, time_steps, gt, proj, outfolder_ltm, unit_scaler=1, deficit=True, gee=False)\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b632a2-b1e6-46c0-928c-f76801b3b7e5",
   "metadata": {},
   "source": [
    "# Visualize Long-term means of Precipitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421c07ef-4ae9-4cbd-93af-873472445fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open borena region shapefile \n",
    "shp_file = Path() / 'CDI_data' / 'roi_info' / 'Borena_outline.geojson'\n",
    "\n",
    "shp = gpd.read_file(str(shp_file))\n",
    "\n",
    "# make sure CRS is lat/lon\n",
    "shp = shp.to_crs(epsg=4326)\n",
    "proj_map = ccrs.PlateCarree()\n",
    "\n",
    "print(f'Preparing monthly LTM precipitation maps [...]\\n')\n",
    "\n",
    "fig, axes = plt.subplots(\n",
    "    4, 3,\n",
    "    figsize=(12, 16),\n",
    "    subplot_kw={\"projection\": proj_map},\n",
    "    constrained_layout=True)\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    da_month = P_ltm_ds[i+1]\n",
    "    \n",
    "    norm = colors.Normalize(vmin=0, vmax=160)\n",
    "\n",
    "    # precipitation plot\n",
    "    im = ax.imshow(da_month, \n",
    "              transform=proj_map, \n",
    "              cmap='Blues', \n",
    "              extent=(extent[0], extent[2], extent[1], extent[3]),\n",
    "              norm=norm)\n",
    "    \n",
    "    # shapefile overlay\n",
    "    shp.boundary.plot(\n",
    "        ax=ax,\n",
    "        edgecolor=\"black\",\n",
    "        linewidth=1)\n",
    "\n",
    "    # titles\n",
    "    month_name = calendar.month_name[i+1]\n",
    "    ax.set_title(month_name)\n",
    "    \n",
    "    gl = ax.gridlines(\n",
    "        crs=ccrs.PlateCarree(),\n",
    "        draw_labels=True,\n",
    "        linewidth=0.5,\n",
    "        color=\"gray\",\n",
    "        alpha=0.6,\n",
    "        linestyle=\"--\")\n",
    "\n",
    "    gl.top_labels = False\n",
    "    gl.right_labels = False\n",
    "    gl.xlabel_style = {\"size\": 9}\n",
    "    gl.ylabel_style = {\"size\": 9}\n",
    "\n",
    "# shared colorbar\n",
    "cbar = fig.colorbar(\n",
    "        im,\n",
    "        ax=axes,\n",
    "        orientation=\"horizontal\",\n",
    "        fraction=0.05,\n",
    "        pad=0.05)\n",
    "\n",
    "cbar.set_label(\"Precipitation (mm/month)\")\n",
    "\n",
    "fig.suptitle(f\"Long-term means (LTM) Monthly Precipitation\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a29bf0-8716-4653-94c3-e57d4f63ae3d",
   "metadata": {},
   "source": [
    "## 1.2 Calculation of Precipitation during IP (3-month period)\n",
    "Once LTM data is produced, we can calculate the actual conditions for the diferent interest periods (IP) i.e. 3 month periods.\n",
    "\n",
    "Again, if the IP results were already produced you can directly import them by setting ip_produced=True. If it is the first time calculating or you want to calculate it again set ip_produced=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f5e63a-385e-428f-a999-4df4bddedd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "outfolder_ip = Path() / 'CDI_data' / 'inputs_downloads' / 'Precip' / 'IP'\n",
    "\n",
    "ip_produced = False\n",
    "\n",
    "if ip_produced:\n",
    "    # get mean IP\n",
    "    mean_ip_folder = outfolder_ip / 'mean'\n",
    "    mean_ip_list = sorted(list(mean_ip_folder.glob('*.tif')))\n",
    "    P_ip_ds = gu.rasterlist2dict(mean_ip_list)\n",
    "\n",
    "    # remove any dates outside of interest period\n",
    "    dates_to_remove = [key for key in P_ip_ds if not (pd.to_datetime(start_date) <= key <= pd.to_datetime(end_date))]\n",
    "    # Removing the keys\n",
    "    for date in dates_to_remove:\n",
    "        del P_ip_ds[date]\n",
    "    \n",
    "    # get RL data\n",
    "    rl_ip_folder = outfolder_ip / 'RL'\n",
    "    mean_rl_list = sorted(list(rl_ip_folder.glob('*.tif')))\n",
    "    P_rl_ip_ds = gu.rasterlist2dict(mean_rl_list)\n",
    "\n",
    "    # remove any dates outside of interest period\n",
    "    dates_to_remove = [key for key in P_rl_ip_ds if not (pd.to_datetime(start_date) <= key <= pd.to_datetime(end_date))]\n",
    "    # Removing the keys\n",
    "    for date in dates_to_remove:\n",
    "        del P_rl_ip_ds[date]\n",
    "    \n",
    "\n",
    "else:\n",
    "    P_ip_ds, P_rl_ip_ds = cdi.compute_ip(da, time_steps, gt, proj, outfolder_ip, unit_scaler=1, deficit=True, gee=False)\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7d5db6-2b75-4d21-843c-ef1b351ef003",
   "metadata": {},
   "source": [
    "#### 1.3 PDI calculation\n",
    "Once we have both the LTM and IP values for precipitation, we can calculate the precipitation drought index (PDI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b75b65d-f56d-426f-8b83-2569c19c3415",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1.3 calculate PDI\n",
    "outfolder = Path() / 'CDI_data' / 'drought_indices'\n",
    "pdi = cdi.calc_pdi(P_ip_ds, P_rl_ip_ds, P_ltm_ds, P_rl_ltm_ds, gt, proj, outfolder)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56be72b-4d65-4e1b-a097-e1f702324edd",
   "metadata": {},
   "source": [
    "## Visualize the PDI results\n",
    "\n",
    "We can visualize 1-year of data. Again by default we will use 2021 as example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0075c8f-92da-48a7-8fa3-879ffd618817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert output list to xarray dataset\n",
    "pdi_times = pd.to_datetime(list(pdi.keys()))\n",
    "pdi_values = np.stack(list(pdi.values()), axis=0)\n",
    "\n",
    "pdi_xr = xr.DataArray(\n",
    "    pdi_values,\n",
    "    coords={\n",
    "        \"time\": pdi_times,\n",
    "        \"latitude\": lats,\n",
    "        \"longitude\": longs,\n",
    "    },\n",
    "    dims=(\"time\", \"latitude\", \"longitude\"),\n",
    "    name=\"PDI\",\n",
    ")\n",
    "\n",
    "# select year to visualize \n",
    "year = 2021\n",
    "\n",
    "# filter the data array to year selected \n",
    "pdi_year = pdi_xr.sel(time=str(year))\n",
    "pdi_year = pdi_year.rio.write_crs(\"EPSG:4326\")\n",
    "\n",
    "\n",
    "print(f'Preparing PDI maps for {year}...\\n')\n",
    "\n",
    "fig, axes = plt.subplots(\n",
    "    4, 3,\n",
    "    figsize=(12, 16),\n",
    "    subplot_kw={\"projection\": proj_map},\n",
    "    constrained_layout=True)\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    da_month = pdi_year.isel(time=i)\n",
    "\n",
    "    # precipitation plot\n",
    "    im = da_month.plot(\n",
    "        ax=ax,\n",
    "        transform=proj_map,\n",
    "        cmap=\"RdYlBu\",\n",
    "        add_colorbar=False)\n",
    "    \n",
    "    # shapefile overlay\n",
    "    shp.boundary.plot(\n",
    "        ax=ax,\n",
    "        edgecolor=\"black\",\n",
    "        linewidth=1)\n",
    "\n",
    "    # titles\n",
    "    month = da_month.time.dt.strftime(\"%B\").item()\n",
    "    ax.set_title(month)\n",
    "\n",
    "    # optional map cosmetics\n",
    "    #ax.coastlines(resolution=\"110m\", linewidth=0.8)\n",
    "    ax.set_extent([\n",
    "        longs.min(),\n",
    "        longs.max(),\n",
    "        lats.min(),\n",
    "        lats.max()])\n",
    "    \n",
    "    gl = ax.gridlines(\n",
    "        crs=ccrs.PlateCarree(),\n",
    "        draw_labels=True,\n",
    "        linewidth=0.5,\n",
    "        color=\"gray\",\n",
    "        alpha=0.6,\n",
    "        linestyle=\"--\")\n",
    "\n",
    "    gl.top_labels = False\n",
    "    gl.right_labels = False\n",
    "    gl.xlabel_style = {\"size\": 9}\n",
    "    gl.ylabel_style = {\"size\": 9}\n",
    "\n",
    "# shared colorbar\n",
    "cbar = fig.colorbar(\n",
    "        im,\n",
    "        ax=axes,\n",
    "        orientation=\"horizontal\",\n",
    "        fraction=0.05,\n",
    "        pad=0.05)\n",
    "\n",
    "cbar.set_label(\"Precipitation Drought Index (PDI) (-)\")\n",
    "\n",
    "fig.suptitle(f\"Monthly PDI for {year}\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3076e692-1605-4fbf-b2b5-f4411f7dc0eb",
   "metadata": {},
   "source": [
    "# 2. Temperature Drought Index (TDI)  \n",
    "Now, we do a very similar procedure with the air temperature data\n",
    "\n",
    "## Extract Air Temperature data from ERA5\n",
    "We will use the same xarray dataset already opened for precipitation but slice it for air temperature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5304569-d14c-43c0-93d8-71a511798495",
   "metadata": {},
   "outputs": [],
   "source": [
    "ta = ds.t2m.astype(\"float32\")\n",
    "ta.attrs[\"units\"] = \"K\"\n",
    "ta_borena = ta.sel(**{\"latitude\": slice(upper_left[0], lower_right[0]), \"longitude\": slice(upper_left[1], lower_right[1])})\n",
    "## compute monthly averages\n",
    "ta_borena_monthly = ta_borena.resample(valid_time=\"MS\").mean()\n",
    "# select time petiod\n",
    "ta_timeperiod = ta_borena_monthly.sel(valid_time=slice(start_date, end_date))\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca67315-a782-4b7b-b0d7-d8a5e0ef77ff",
   "metadata": {},
   "source": [
    "## Compute air temperature to memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6748dab-8ec7-4352-9b1f-c9410ba5413f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print('Computing dataset selection to memory [...]')\n",
    "da = ta_timeperiod.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885ab246-4115-4f6d-9e53-f430dc439ab9",
   "metadata": {},
   "source": [
    "## 2.1 Calculation of Long-term-mean (LTM) of air temperature\n",
    "We will use the same xarray dataset already opened for precipitation but slice it for air temperature\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7b27c8-2f5c-449b-bd7b-b924a94076e4",
   "metadata": {},
   "source": [
    "#### Get all time steps and set outfolder path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02895f77-1b78-4f84-8178-62f228c07fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "da = da.rename({'valid_time': 'time'})\n",
    "# get all time steps\n",
    "time_steps = pd.to_datetime(da['time'].values)\n",
    "years = np.array(time_steps.year)\n",
    "\n",
    "# select output folder for Ta\n",
    "outfolder_ltm = Path() / 'CDI_data' / 'inputs_downloads' / 'Ta' / 'LTM'\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13c89bc-6abd-43ca-8d9e-6f194f4cdb54",
   "metadata": {},
   "source": [
    "Since calculating the LTM may take some time, if the LTM were already produced you can directly import them by setting ltm_produced=True. If it is the first time calculating or you want to calculate it again set ltm_produced=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83161c0b-b8d5-4df1-ba31-21416c9aea6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ltm_produced = False\n",
    "if ltm_produced:\n",
    "    # get mean\n",
    "    mean_ltm_folder = outfolder_ltm / 'mean'\n",
    "    mean_img_list = sorted(list(mean_ltm_folder.glob('*.tif')))\n",
    "    Ta_ltm_ds = gu.rasterlist2dict(mean_img_list)\n",
    "    \n",
    "    # get RL data\n",
    "    rl_img_folder = outfolder_ltm / 'RL'\n",
    "    rl_img_list = sorted(list(rl_img_folder.glob('*.tif')))\n",
    "    Ta_rl_ltm_ds = gu.rasterlist2dict(rl_img_list)\n",
    "\n",
    "else:\n",
    "    Ta_ltm_ds, Ta_rl_ltm_ds = cdi.compute_ltm(da, time_steps, gt, proj, outfolder_ltm, unit_scaler=1, deficit=False, gee=False)\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb90a8fe-6e51-4339-9cf1-db1ba6beff6d",
   "metadata": {},
   "source": [
    "# Visualize Long-term-means of air temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd5b81e-fa3f-48dd-80c4-3b41e99b6aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open borena region shapefile \n",
    "shp_file = Path() / 'CDI_data' / 'roi_info' / 'Borena_outline.geojson'\n",
    "\n",
    "shp = gpd.read_file(str(shp_file))\n",
    "\n",
    "# make sure CRS is lat/lon\n",
    "shp = shp.to_crs(epsg=4326)\n",
    "proj_map = ccrs.PlateCarree()\n",
    "\n",
    "print(f'Preparing monthly LTM of air temperature maps [...]\\n')\n",
    "\n",
    "fig, axes = plt.subplots(\n",
    "    4, 3,\n",
    "    figsize=(12, 16),\n",
    "    subplot_kw={\"projection\": proj_map},\n",
    "    constrained_layout=True)\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    da_month = Ta_ltm_ds[i+1]\n",
    "    \n",
    "    norm = colors.Normalize(vmin=20, vmax=35)\n",
    "\n",
    "    # precipitation plot\n",
    "    im = ax.imshow(da_month-273.15, \n",
    "              transform=proj_map, \n",
    "              cmap='Reds', \n",
    "              extent=(extent[0], extent[2], extent[1], extent[3]),\n",
    "              norm=norm)\n",
    "    \n",
    "    # shapefile overlay\n",
    "    shp.boundary.plot(\n",
    "        ax=ax,\n",
    "        edgecolor=\"black\",\n",
    "        linewidth=1)\n",
    "\n",
    "    # titles\n",
    "    month_name = calendar.month_name[i+1]\n",
    "    ax.set_title(month_name)\n",
    "    \n",
    "    gl = ax.gridlines(\n",
    "        crs=ccrs.PlateCarree(),\n",
    "        draw_labels=True,\n",
    "        linewidth=0.5,\n",
    "        color=\"gray\",\n",
    "        alpha=0.6,\n",
    "        linestyle=\"--\")\n",
    "\n",
    "    gl.top_labels = False\n",
    "    gl.right_labels = False\n",
    "    gl.xlabel_style = {\"size\": 9}\n",
    "    gl.ylabel_style = {\"size\": 9}\n",
    "\n",
    "# shared colorbar\n",
    "cbar = fig.colorbar(\n",
    "        im,\n",
    "        ax=axes,\n",
    "        orientation=\"horizontal\",\n",
    "        fraction=0.05,\n",
    "        pad=0.05)\n",
    "\n",
    "cbar.set_label(\"Mean Air Temperature (Celcius)\")\n",
    "\n",
    "fig.suptitle(f\"Long-term means (LTM) Air Temperature\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc41deb9-112c-47ef-a6a6-d6c70112410c",
   "metadata": {},
   "source": [
    "## 2.2 Air Temperature during IP\n",
    "Once LTM data is produced, we can calculate the actual conditions for the diferent interest periods (IP). This is the condition of the 3-month moving window for each month assessed in the time window selected. \n",
    "\n",
    "Again, if the IP results were already produced you can directly import them by setting ip_produced=True. If it is the first time calculating or you want to calculate it again set ip_produced=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e491a7-1573-4746-bf73-2cb4c34d35c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set output folder to store IP results\n",
    "outfolder_ip = Path() / 'CDI_data' / 'inputs_downloads' / 'Ta' / 'IP'\n",
    "\n",
    "ip_produced = False\n",
    "\n",
    "if ip_produced:\n",
    "    # get mean IP\n",
    "    mean_ip_folder = outfolder_ip / 'mean'\n",
    "    mean_ip_list = sorted(list(mean_ip_folder.glob('*.tif')))\n",
    "    Ta_ip_ds = gu.rasterlist2dict(mean_ip_list)\n",
    "    \n",
    "    # remove any dates outside of interest period\n",
    "    dates_to_remove = [key for key in Ta_ip_ds if not (pd.to_datetime(start_date) <= key <= pd.to_datetime(end_date))]\n",
    "    # Removing the keys\n",
    "    for date in dates_to_remove:\n",
    "        del Ta_ip_ds[date]\n",
    "\n",
    "    # get RL data\n",
    "    rl_ip_folder = outfolder_ip / 'RL'\n",
    "    mean_rl_list = sorted(list(rl_ip_folder.glob('*.tif')))\n",
    "    Ta_rl_ip_ds = gu.rasterlist2dict(mean_rl_list)\n",
    "\n",
    "    # remove any dates outside of interest period\n",
    "    dates_to_remove = [key for key in Ta_rl_ip_ds if not (pd.to_datetime(start_date) <= key <= pd.to_datetime(end_date))]\n",
    "    # Removing the keys\n",
    "    for date in dates_to_remove:\n",
    "        del Ta_rl_ip_ds[date]\n",
    "\n",
    "else:\n",
    "    Ta_ip_ds, Ta_rl_ip_ds = cdi.compute_ip(da, time_steps, gt, proj, outfolder_ip, unit_scaler=1, deficit=False, gee=False)\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff595735-eb9b-4fee-8862-eab125d298fb",
   "metadata": {},
   "source": [
    "## 2.3 Calculate TDI\n",
    "Once we have both the LTM and IP values for precipitation, we can calculate the TDI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d249cc-4002-4d44-9d0a-9877c850a3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get maximum air temperature during whole period to normalize air temperature when computing TDI\n",
    "Ta_ar = da.values\n",
    "Ta_max_ar = np.nanmax(Ta_ar)\n",
    "\n",
    "outfolder = Path() / 'CDI_data' / 'drought_indices'\n",
    "tdi = cdi.calc_tdi(Ta_ip_ds, Ta_rl_ip_ds, Ta_ltm_ds, Ta_rl_ltm_ds, Ta_max_ar, gt, proj, outfolder)\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1edb479-45f8-40e3-9832-d318d0aec1e2",
   "metadata": {},
   "source": [
    "## 2.4 Visualize TDI results\n",
    "\n",
    "By default the year 2021 is selected. Change to any year within temporal window. This will show monthly mean values for that year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b584269-4405-4878-bf18-ebc2012c4e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert output list to xarray dataset\n",
    "tdi_times = pd.to_datetime(list(tdi.keys()))\n",
    "tdi_values = np.stack(list(tdi.values()), axis=0)\n",
    "\n",
    "tdi_xr = xr.DataArray(\n",
    "    tdi_values,\n",
    "    coords={\n",
    "        \"time\": tdi_times,\n",
    "        \"latitude\": lats,\n",
    "        \"longitude\": longs,\n",
    "    },\n",
    "    dims=(\"time\", \"latitude\", \"longitude\"),\n",
    "    name=\"PDI\",\n",
    ")\n",
    "\n",
    "# select year to visualize \n",
    "year = 2021\n",
    "\n",
    "# filter the data array to year selected \n",
    "tdi_year = tdi_xr.sel(time=str(year))\n",
    "tdi_year = tdi_year.rio.write_crs(\"EPSG:4326\")\n",
    "\n",
    "\n",
    "print(f'Preparing figure of TDI maps for {year}...\\n')\n",
    "\n",
    "fig, axes = plt.subplots(\n",
    "    4, 3,\n",
    "    figsize=(12, 16),\n",
    "    subplot_kw={\"projection\": proj_map},\n",
    "    constrained_layout=True)\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    da_month = tdi_year.isel(time=i)\n",
    "\n",
    "    # precipitation plot\n",
    "    im = da_month.plot(\n",
    "        ax=ax,\n",
    "        transform=proj_map,\n",
    "        cmap=\"RdYlBu\",\n",
    "        add_colorbar=False,\n",
    "    vmin=0.4,\n",
    "    vmax=1.2)\n",
    "    \n",
    "    # shapefile overlay\n",
    "    shp.boundary.plot(\n",
    "        ax=ax,\n",
    "        edgecolor=\"black\",\n",
    "        linewidth=1)\n",
    "\n",
    "    # titles\n",
    "    month = da_month.time.dt.strftime(\"%B\").item()\n",
    "    ax.set_title(month)\n",
    "\n",
    "    # optional map cosmetics\n",
    "    #ax.coastlines(resolution=\"110m\", linewidth=0.8)\n",
    "    ax.set_extent([\n",
    "        longs.min(),\n",
    "        longs.max(),\n",
    "        lats.min(),\n",
    "        lats.max()])\n",
    "    \n",
    "    gl = ax.gridlines(\n",
    "        crs=ccrs.PlateCarree(),\n",
    "        draw_labels=True,\n",
    "        linewidth=0.5,\n",
    "        color=\"gray\",\n",
    "        alpha=0.6,\n",
    "        linestyle=\"--\")\n",
    "\n",
    "    gl.top_labels = False\n",
    "    gl.right_labels = False\n",
    "    gl.xlabel_style = {\"size\": 9}\n",
    "    gl.ylabel_style = {\"size\": 9}\n",
    "\n",
    "# shared colorbar\n",
    "cbar = fig.colorbar(\n",
    "        im,\n",
    "        ax=axes,\n",
    "        orientation=\"horizontal\",\n",
    "        fraction=0.05,\n",
    "        pad=0.05)\n",
    "\n",
    "cbar.set_label(\"Temperature Drought Index (TDI) (-)\")\n",
    "\n",
    "fig.suptitle(f\"Monthly TDI for {year}\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cded78-d0fe-4553-b5c4-a05856e9e5d7",
   "metadata": {},
   "source": [
    "# 3. VDI estimation\n",
    "\n",
    "In this case of VDI, we will use NDVI as a proxie of vegetation vigor. We will process the monthly values from the 8-day surface reflectance product from MODIS through the STAC browser of the [Microsoft Planetry Computer](https://planetarycomputer.microsoft.com/dataset/modis-09Q1-061)\n",
    "\n",
    "## 3.1 Deriving monthly mean NDVI\n",
    "\n",
    "### 3.1.1 Extract MODIS 8-day NDVI using Cubo and STAC\n",
    "\n",
    "As a first step we need to get monthly mean NDVI from these 8-day products from Microsoft Planetary Computer (STAC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276e5a13-cf83-4824-a878-1f7a05df46c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ndvi product we use microsoft planetery computer STAC\n",
    "stac = 'https://planetarycomputer.microsoft.com/api/stac/v1'\n",
    "\n",
    "# 8-day surface reflectance (250m)\n",
    "collection = 'modis-09Q1-061'\n",
    "da = cubo.create(lat, lon,\n",
    "                 collection,\n",
    "                 start_date,\n",
    "                 end_date,\n",
    "                 bands=['sur_refl_b01', 'sur_refl_b02', 'sur_refl_qc_250m'],\n",
    "                 edge_size=700, # 1400 roughly size of roi in using 250m resolution\n",
    "                 resolution=500,\n",
    "                 stac=stac\n",
    "                 )\n",
    "\n",
    "da = da.assign_coords(epsg=da.attrs['epsg'])\n",
    "da = da.rio.write_crs(f\"EPSG:{da['epsg'].data}\")\n",
    "# get georeferencing metadata\n",
    "epsg_code = da.attrs['epsg']\n",
    "center_x = da.attrs['central_x']\n",
    "center_y = da.attrs['central_y']\n",
    "width = da.attrs['edge_size']\n",
    "pixel_size = da.attrs['resolution']\n",
    "\n",
    "gt = gu.calculate_geotransform(center_x, center_y, pixel_size, width, width)\n",
    "proj = CRS.from_epsg(epsg_code).wkt\n",
    "# use start datetime as time (some issues with original time domain)\n",
    "da['time'] = da['start_datetime']\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9182613b-749c-4eaf-988e-7d89ceefe95a",
   "metadata": {},
   "source": [
    "#### 3.1 Computing monthly mean NDVI\n",
    "\n",
    "As a first step we need to get monthly mean NDVI from these 8-day products. If these data were already produced, simply set ndvi_produced=True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31edb1b3-cdc9-4bcf-bb50-5fc62b5c91b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set to true if data is already produced in local\n",
    "ndvi_produced = True\n",
    "\n",
    "outfolder_ndvi = Path() / 'CDI_data' / 'inputs_downloads' / 'ndvi'\n",
    "if ndvi_produced:\n",
    "    mean_folder = outfolder_ndvi / 'monthly_rasters'\n",
    "    mean_list = sorted(list(mean_folder.glob('*.tif')))\n",
    "    ndvi_monthly = gu.rasterlist2xarray(mean_list)\n",
    "else:\n",
    "    print(f'Processing monthly NDVI for between {start_date} and {end_date} (may take some minutes)...\\n')\n",
    "    ndvi_monthly = cdi.compute_ndvi_monthly(da, start_date, end_date, gt, proj, outfolder_ndvi)\n",
    "\n",
    "# convert xarray to DataArray to match cubo array type\n",
    "# Define dimensions and coordinates\n",
    "dims = ('time', 'x', 'y')  # Example dimensions\n",
    "coords = {'time': ndvi_monthly['time'].values, 'x': ndvi_monthly['x'].values, 'y': ndvi_monthly['y'].values}\n",
    "# store in xarray DataArray\n",
    "da_ndvi = xr.DataArray(data=ndvi_monthly.to_array(), dims=dims, coords=coords)\n",
    "date_mask = np.logical_and(da_ndvi['time'] >= pd.to_datetime(start_date), da_ndvi['time'] <= pd.to_datetime(end_date))\n",
    "da_ndvi = da_ndvi[date_mask, :, :]\n",
    "# sort data array by time\n",
    "da_ndvi = da_ndvi.sortby('time')\n",
    "\n",
    "time_steps = pd.to_datetime(da_ndvi['time'])\n",
    "years = time_steps.year\n",
    "months = time_steps.month\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70d70eb-3f2d-4416-bcbc-d9b8c9dd789a",
   "metadata": {},
   "source": [
    "## 3.2 Calculation of Long-term-mean (LTM) of NDVI\n",
    "we will use the output of the monthly mean processed above to calculate the LTM, which was stored in xarray dataset similar to maintain consistency with the processing of precipitation and air temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6cc703-f295-4680-b459-2a18db9701ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set output folder\n",
    "outfolder_ndvi_ltm = Path() / 'CDI_data' / 'inputs_downloads' / 'ndvi'/'LTM'\n",
    "\n",
    "ltm_produced = False\n",
    "if ltm_produced:\n",
    "    # get mean data\n",
    "\n",
    "    mean_ltm_folder = outfolder_ndvi_ltm / 'mean'\n",
    "    mean_img_list = sorted(list(mean_ltm_folder.glob('*.tif')))\n",
    "    ndvi_ltm_ds = gu.rasterlist2dict(mean_img_list)\n",
    "    \n",
    "    # get RL data\n",
    "    rl_img_folder = outfolder_ndvi_ltm / 'RL'\n",
    "    rl_img_list = sorted(list(rl_img_folder.glob('*.tif')))\n",
    "    ndvi_rl_ltm_ds = gu.rasterlist2dict(rl_img_list)\n",
    "\n",
    "else:\n",
    "    ndvi_ltm_ds, ndvi_rl_ltm_ds = cdi.compute_ltm(da_ndvi, time_steps, gt, proj, outfolder_ndvi_ltm, unit_scaler=1, deficit=True)\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b0f9c4-f175-4545-85cf-76a3fb32456e",
   "metadata": {},
   "source": [
    "## 3.3. NDVI during Interest Periods (IP)\n",
    "Once LTM data is produced, we can calculate the actual conditions for the diferent interest periods (IP)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e76f9b-2a18-47e1-922f-2eecc9a10969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select output folder\n",
    "outfolder_ndvi_ip = Path() / 'CDI_data' / 'inputs_downloads' / 'ndvi' / 'IP'\n",
    "\n",
    "ip_produced = True\n",
    "\n",
    "if ip_produced:\n",
    "    # get mean IP\n",
    "    mean_ip_folder = outfolder_ndvi_ip / 'mean'\n",
    "    mean_ip_list = sorted(list(mean_ip_folder.glob('*.tif')))\n",
    "    ndvi_ip_ds = gu.rasterlist2dict(mean_ip_list)\n",
    "    \n",
    "    # remove any dates outside of interest period\n",
    "    dates_to_remove = [key for key in ndvi_ip_ds if not (pd.to_datetime(start_date) <= key <= pd.to_datetime(end_date))]\n",
    "    # Removing the keys\n",
    "    for date in dates_to_remove:\n",
    "        del ndvi_ip_ds[date]\n",
    "\n",
    "    \n",
    "    # get RL data\n",
    "    rl_ip_folder = outfolder_ndvi_ip / 'RL'\n",
    "    mean_rl_list = sorted(list(rl_ip_folder.glob('*.tif')))\n",
    "    ndvi_rl_ip_ds = gu.rasterlist2dict(mean_rl_list)\n",
    "\n",
    "    # remove any dates outside of interest period\n",
    "    dates_to_remove = [key for key in ndvi_rl_ip_ds if not (pd.to_datetime(start_date) <= key <= pd.to_datetime(end_date))]\n",
    "    # Removing the keys\n",
    "    for date in dates_to_remove:\n",
    "        del ndvi_rl_ip_ds[date]\n",
    "\n",
    "\n",
    "else:\n",
    "    ndvi_ip_ds, ndvi_rl_ip_ds = cdi.compute_ip(da_ndvi, time_steps, gt, proj, outfolder_ndvi_ip, deficit=True, unit_scaler=1)\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119923f9-7b70-4156-99a1-cfcd7716bc9c",
   "metadata": {},
   "source": [
    "## 3.4 Compute the Vegetation Drought Index (VDI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d11a0e-be0f-42b9-9b00-dc73f464c9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get minimum NDVI for the entire study period\n",
    "ndvi_ar = da_ndvi.values\n",
    "ndvi_min_ar = np.nanmin(ndvi_ar)\n",
    "ndvi_min = 0.15\n",
    "# select output folder\n",
    "outfolder = Path() / 'CDI_data' / 'drought_indices'\n",
    "\n",
    "# calculate VDI\n",
    "vdi = cdi.calc_vdi(ndvi_ip_ds, ndvi_rl_ip_ds, ndvi_ltm_ds, ndvi_rl_ltm_ds, ndvi_min, gt, proj, outfolder)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60527fcb-bdb5-436f-8f89-f46acc3bb37b",
   "metadata": {},
   "source": [
    "## 3.5 Visualize monthly VDI\n",
    "By default the year 2021 is selected. Change to any year within temporal window. This will show monthly mean values for that year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cc9d7c-a948-4997-8781-95202846ff24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert output list to xarray dataset\n",
    "vdi_times = pd.to_datetime(list(vdi.keys()))\n",
    "vdi_values = np.stack(list(vdi.values()), axis=0)\n",
    "\n",
    "vdi_xr = xr.DataArray(\n",
    "    vdi_values,\n",
    "    coords={\n",
    "        \"time\": vdi_times,\n",
    "        \"y\": da.y.values,\n",
    "        \"x\": da.x.values,\n",
    "    },\n",
    "    dims=(\"time\", \"y\", \"x\"),\n",
    "    name=\"VDI\",\n",
    ")\n",
    "\n",
    "# select year to visualize \n",
    "year = 2021\n",
    "\n",
    "# make sure CRS is lat/lon\n",
    "shp = shp.to_crs(epsg=int(da.epsg.values))\n",
    "proj_map = ccrs.PlateCarree()\n",
    "\n",
    "# filter the data array to year selected \n",
    "vdi_year = vdi_xr.sel(time=str(year))\n",
    "vdi_year = vdi_year.rio.write_crs(f\"EPSG:{int(da.epsg.values)}\")\n",
    "\n",
    "print(f'Preparing figure of VDI maps for {year} (may take some time)... \\n')\n",
    "\n",
    "fig, axes = plt.subplots(4, 3,\n",
    "    figsize=(12, 16),\n",
    "    constrained_layout=True)\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    da_month = vdi_year.isel(time=i)\n",
    "\n",
    "    \n",
    "    # precipitation plot\n",
    "    im = da_month.plot(\n",
    "        ax=ax,\n",
    "        cmap=\"RdYlBu\",\n",
    "        add_colorbar=False,\n",
    "    vmin=0.4,\n",
    "    vmax=1.2)\n",
    "    \n",
    "    # shapefile overlay\n",
    "    shp.boundary.plot(\n",
    "        ax=ax,\n",
    "        edgecolor=\"black\",\n",
    "        linewidth=2)\n",
    "    \n",
    "    # titles\n",
    "    month = da_month.time.dt.strftime(\"%B\").item()\n",
    "    ax.set_title(month)\n",
    "\n",
    "# shared colorbar\n",
    "cbar = fig.colorbar(\n",
    "        im,\n",
    "        ax=axes,\n",
    "        orientation=\"horizontal\",\n",
    "        fraction=0.05,\n",
    "        pad=0.05)\n",
    "\n",
    "cbar.set_label(\"Vegetation Drought Index (TDI) (-)\")\n",
    "\n",
    "fig.suptitle(f\"Monthly VDI for {year}\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04cd2cc-5ad6-479f-8e92-13c8c90d3397",
   "metadata": {},
   "source": [
    "## 4. CDI calculation \n",
    "Now that we have produced the three components of the CDI (PDI, TDI and VDI), we can now merged them together and obtain the final CDI for each of the IPs.\n",
    "\n",
    "### 4.1 Resample all indices to same resolution\n",
    "\n",
    "First, we need to resample all the of the datasets to have a common pixel size, extent and projection. We will use the NDVI files as the template to resample all data to the same pixel size. We will also take advantage to clip the datasets to the region of interest (ROI) over the Borena region. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3db40a-db53-4153-bb34-0e80884c982f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vdi_folder = outfolder / 'VDI'\n",
    "template_file = list(vdi_folder.glob('*.tif'))[0]\n",
    "\n",
    "# file pathname to Borena ROI shapefile\n",
    "roi_file = Path() / 'CDI_data' / 'roi_info' / 'Borena_outline_utm.geojson'\n",
    "\n",
    "pdi_ds, tdi_ds, vdi_ds = cdi.resample_indices(outfolder, roi_file, template_file, start_date, end_date, indices = ['PDI', 'TDI', 'VDI'])\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e167a655-c6d6-4458-95e3-453177e88632",
   "metadata": {},
   "source": [
    "### 4.2 Merge indices to compute CDI\n",
    "Now we can finnaly merge all drought indices to compute the CDI.\n",
    "\n",
    "The CDI is computed as the weighted average of the PDI and VDI and TDI, as shown below on equation:\n",
    "\n",
    "$$\n",
    "CDI = w_{PDI} PDI + w_{TDI}TDI + w_{VDI}VDI\n",
    "$$\n",
    "here w are the weights which are 50% for $w_{PDI}$ and $w_{TDI}$=$w_{VDI}$=25% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601e788b-0fec-4145-98c3-72965f2de349",
   "metadata": {},
   "outputs": [],
   "source": [
    "outfolder = Path() / 'CDI_data' / 'drought_indices'\n",
    "\n",
    "# use template of the ROI image\n",
    "template_folder = outfolder/'VDI'/'ROI'\n",
    "template_file = list(template_folder.glob('*.tif'))[0]\n",
    "# get geotransform and projection data from ROI image\n",
    "proj, gt, _ , _ , _ , _ , _ = gu.raster_info(str(template_file))\n",
    "\n",
    "# compute CDI\n",
    "#cdi_ds = cdi.calc_cdi(pdi_ds, tdi_ds, vdi_ds, gt, proj, outfolder)\n",
    "cdi_ds = cdi.calc_cdi_img(start_date, end_date, gt, proj, outfolder)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915b64c9-48c2-496f-941a-a2b5bd7f1e3a",
   "metadata": {},
   "source": [
    "## 4.3 Visualizing CDI results\n",
    "Here we can visualize some of the results using Leafmap\n",
    "\n",
    "CDI values higher than 1 indicates no drought warning while any CDI value below 1 should be considered as possible drought warning: \n",
    "\n",
    "![CDI values](images/cdi_value_range.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc39905-86da-4421-a385-3df07f1a2937",
   "metadata": {},
   "outputs": [],
   "source": [
    "from leafmap import leafmap\n",
    "import rasterio\n",
    "\n",
    "# output CDI folder\n",
    "cdi_folder =  outfolder/'CDI'\n",
    "\n",
    "# choose image to show\n",
    "# choose year and month\n",
    "year = 2021\n",
    "month = 3 \n",
    "\n",
    "img = cdi_folder / f'CDI_IP_{year}_{month}.tif'\n",
    "m = leafmap.Map(center=(lat, lon), zoom=8)\n",
    "\n",
    "# add CDI raster from march \n",
    "fid = rasterio.open(str(img))\n",
    "m.add_raster(fid, colormap=\"Spectral\", layer_name=f\"{year} month {month}\", vmin=0.4, vmax=1)\n",
    "\n",
    "# add CDI raster from Sept \n",
    "month = 9\n",
    "img = cdi_folder / f'CDI_IP_{year}_{month}.tif'\n",
    "fid2 = rasterio.open(str(img))\n",
    "m.add_raster(fid2, colormap=\"Spectral\", layer_name=f\"{year} month {month}\", vmin=0.4, vmax=1)\n",
    "\n",
    "params = {\n",
    "    \"width\": 4.0,\n",
    "    \"height\": 0.3,\n",
    "    \"vmin\": 0.4,\n",
    "    \"vmax\": 1,\n",
    "    \"cmap\": \"Spectral\",\n",
    "    \"label\": \"CDI ()\",\n",
    "    \"orientation\": \"horizontal\",\n",
    "}\n",
    "m.add_colormap(position='bottomright', **params)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0883e34c-6e88-4334-a31b-c9e25c9884b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
